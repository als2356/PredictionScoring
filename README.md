# Prediction Scoring
In this `R` notebook, we describe and implement some statistical methods to handle prediction scoring.  In the NGS2 program, we see this methodology as helping ETE teams to compare predictions to observed results from the experiments in each cycle.  For example, we might be interested in comparing:

* predictions or hypotheses from *preregistration materials* to *observed experimental data*
* predictions based on *observed cycle one data* to *observed experimental data from cycle two*

We have packaged this methodology as an easy to use function in `R` and can see this type of analysis being beneficial to a variety of researchers, outside of the NGS2 program.  For example, any researchers interested in evaluating pre-registered hypotheses or any researchers working with experimental data that is collected in cycles or stages, may find this discussion helpful.

Our approach is insipred by Cook, Gelman & Rubin (2006)'s methodology for software validation of Bayesian models.
